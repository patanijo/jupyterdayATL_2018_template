{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {{cookiecutter.project_name}}\n",
    "\n",
    "##### Version 0.1\n",
    "#####  Author: {{cookiecutter.author_name}}\n",
    "##### email: {{cookiecutter.author_email}}\n",
    "##### Date: {% now 'local', '%d/%m/%Y' %}\n",
    "\n",
    "##### Contributors: contributor1, contributor2, ..., contributor n\n",
    "\n",
    "Note: Depending on the length of the analysis, this notebook can be broken into multiple sections. Where "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "Identify a business problem or question and agree with stakeholders about the questions and hypotheses this analytic study will be trying to answer.\n",
    "\n",
    "### Background\n",
    "* What is known about the problem at the beginning of the project?\n",
    "* Any resources, constraints or assumptions?\n",
    "* Who is the customer for this project.\n",
    "\n",
    "### Goals & Objectives\n",
    "* What are the goals and objective for doing this analytic?\n",
    "* What is the business value for a successful implementation of this analytic?\n",
    "* What are the specific required outputs of this analytic.\n",
    "\n",
    "### Success Criteria\n",
    "* Identify specific metrics that will be used to assess the success of this analytic.\n",
    "\n",
    "For example:\n",
    "\n",
    "1.\tMinimum lead time of …….\n",
    "2.\tFalse alarm rate should be less than …..%.\n",
    "3.\tPOD should be at least …. %\n",
    "4.\tSensor issues should not trigger false alarms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "### Data Sources\n",
    "Identify all data sources that can or will be used. This typically includes the following:\n",
    "\n",
    "* time series data\n",
    "* lists of failure events\n",
    "\n",
    "### Descriptive Data Analysis\n",
    "\n",
    "* What is the data that will be used in analytic development, i.e. tags, variables, units of measure, etc.\n",
    "* What format is the data in, what is size of the data\n",
    "* Descriptions of time series data should include include asset ID, timestamps, tags, frequency and other information as required.\n",
    "* List details of tag availability across the applicable assets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "* Descriptive Statistics of the data sets.\n",
    "*  Include graphs of the data set that aid in deeper understanding or interpretation of the data. Typical content may include box plots, histograms, scatter plots, correlation plots, heat maps, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EDA code here.  Any plots should be saved int the figures directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "* How is the data captured?\n",
    "* How will the data be stored, accessed, cleaned, processed, and scheduled?\n",
    "* A flowchart or outline of processing steps may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the raw data via code if accessible. Small data sets can be stored in the data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "* Identify how to clean, transform and deal with common data quality issues, such as missing data, gaps. etc. Identify any data that had to be removed and in addition any missing data that had to be imputed.\n",
    "* Any additional processing needed to create the final dataset, i.e. data that will be used for modeling. This can include things like merging multiple datasets or aggregation.\n",
    "* Describe derived data and any feature calculations\n",
    "* Provide details of data used for training, validation, testing.\n",
    "* If data is of moderate size, save an intermediate of the raw data into the results subdirectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Analysis\n",
    "* What techniques, modeling methods, domain specific calculations have been used?\n",
    "* Are there specific parameters that have been used, tried, or optimized?\n",
    "\n",
    "#### Methods\n",
    "\n",
    "#### Model Training and Tuning\n",
    "\n",
    "* What modeling method(s) or engineering calculations will be used?\n",
    "* List any specific modeling assumptions.\n",
    "* List any model parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analysis and Machine Learning Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Evaluation\n",
    "### Model Performance Assessment and Comparisons\n",
    "* For anomaly detection type analytics, calculate estimated POD and false positive rate (% and alarms per year)\n",
    "* List artifacts of this analytic.\n",
    "\n",
    "__Analytic Performance on Faulty Units__\n",
    "\n",
    "#### Sample Tabular Output\n",
    "| Parameter     | Value       |\n",
    "| ------------- |-------------|\n",
    "| # of Units    | 0           |\n",
    "| # of units evaluated |    0 |\n",
    "| # of units with alarms |  0 |\n",
    "| # of units with no alarms | 0 |\n",
    "\n",
    "__Analytic Performance on Healthy Units__\n",
    "\n",
    "| Parameter       | Value    |\n",
    "| ------------- |-------------|\n",
    "| # of Units    | 0 |\n",
    "| # of units evaluated  | 0  |\n",
    "| # of units with alarms |     0  |\n",
    "| # of units with no alarms | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate performance metrics chosen on a test set or via cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "* How do we embed these results into the business and/or future decision-making processes?\n",
    "* What is the output of this analytic;  i.e. report, i.e. dashboard, production analytic?\n",
    "\n",
    "### Applicability\n",
    "\n",
    "* What type of assets does this study apply to?\n",
    "* Which failure modes (reference NERC) does this analytic provide coverage for.\n",
    "\n",
    "\n",
    "## Conclusions and Future Work\n",
    "* Did the analytic meet success criteria identified in the project? If no, why not?\n",
    "Provide insights and storytelling feedback\n",
    "* How could we do a better capture data in the future, either with new data or improving existing methods.\n",
    "* What else went right or wrong?\n",
    "\n",
    "\n",
    "## References\n",
    "1. CRISP-DM 1.0 Step-by-step data mining guide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
